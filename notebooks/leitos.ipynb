{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pathlib\n",
    "import sqlalchemy\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = str(pathlib.Path(os.path.abspath('')).parent.resolve())\n",
    "file_dir    = str(os.path.abspath(''))\n",
    "\n",
    "load_dotenv(project_dir+'/config/config_file.env')\n",
    "max_request_retries = int(os.getenv('MAX_REQUEST_RETRIES'))\n",
    "request_timeout     = int(os.getenv('REQUEST_TIMEOUT'))\n",
    "\n",
    "logging.basicConfig(filename=project_dir+'/log_file.log', level=logging.DEBUG)\n",
    "\n",
    "class MaxRequestRetries(Exception):\n",
    "    pass\n",
    "class InvalidFormatError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_dataframe(engine: sqlalchemy.engine, df: pd.DataFrame, filedir: str, \n",
    "                       table_name: str, format: str ='excel', index: bool =False) -> None:\n",
    "    \"\"\" Exporta o dataframe para o formato especificado\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    df: pandas.Dataframe\n",
    "        Dataframe para ser exportado\n",
    "    filedir: string\n",
    "        Diretorio da pasta para output\n",
    "    table_name: string\n",
    "        Nome do arquivo output, sem a extensão\n",
    "    format: string\n",
    "        Formato do arquivo output, cujas opções estão no dicionário dict_exportar\n",
    "    index: boolean\n",
    "        Quando igual a True, a coluna de índice do Dataframe irá paro arquivo output\n",
    "    engine: sqlalchemy.engine\n",
    "        Conexão com o banco de dados, quando format='SQL'\n",
    "\n",
    "    Retorno:\n",
    "    ----------\n",
    "        None\n",
    "    \"\"\"\n",
    "    dict_exportar = {\n",
    "        'EXCEL'  : [df.to_excel,'.xlsx'],\n",
    "        'CSV'    : [df.to_csv,'.csv'],\n",
    "        'PARQUET': [df.to_parquet,'.parquet'],\n",
    "        'PICKLE' : [df.to_pickle,'.pickle'],\n",
    "        'JSON'   : [df.to_json,'.json'],\n",
    "        'SQL'    : [df.to_sql,'']\n",
    "    }\n",
    "    \n",
    "    format = format.upper()\n",
    "    try:\n",
    "        export_func, extension = dict_exportar[format]\n",
    "    except KeyError:\n",
    "        logging.ERROR(f\"\"\"{datetime.now()}: Formato inválido para exportação. Os formatos disponíveis são: {list(dict_exportar.keys())}.\"\"\")\n",
    "        raise InvalidFormatError(f'Formato inválido para exportação. Os formatos disponíveis são: {list(dict_exportar.keys())}.')\n",
    "    \n",
    "    if format == 'SQL':\n",
    "        export_func(name = table_name,con=engine,if_exists='append',index=index)\n",
    "    else:\n",
    "        export_func(filedir+'/'+table_name+extension,index=index)\n",
    "    return None\n",
    "\n",
    "def listar_links_tabelas_por_uf(uf: str) -> List[str]:\n",
    "    \"\"\" Extrai os links das paginas que contém as tabelas de leitos, dado UF\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    uf: string\n",
    "        Sigla do UF para coleta da tabela de leitos\n",
    "    \n",
    "    Retorno\n",
    "    ----------\n",
    "    links_tabelas: list[string]\n",
    "        Lista com os links das paginas que contém as tabelas de leitos\n",
    "    \n",
    "    \"\"\"\n",
    "    codigo_ibge : dict = {'RJ':33, 'SP':35, 'ES':32, 'MG':31, 'SC':42,\n",
    "                          'RS':43, 'PR':41, 'DF':53, 'GO':52, 'MT':51,\n",
    "                          'MS':50, 'MA':21, 'PI':22, 'CE':23, 'RN':24,\n",
    "                          'PB':25, 'PE':26, 'AL':27, 'SE':28, 'BA':29,\n",
    "                          'RO':11, 'AC':12, 'AM':13, 'RR':14, 'PA':15,\n",
    "                          'AP':16, 'TO':17}\n",
    "    \n",
    "    url = f'http://cnes2.datasus.gov.br/Mod_Ind_Tipo_Leito.asp?VEstado={codigo_ibge[uf]}'\n",
    "    \n",
    "    request_retries     = 0\n",
    "    sucess              = False\n",
    "    while not sucess:\n",
    "        try:\n",
    "            page_source       = requests.get(url,'lxml',timeout=request_timeout).text\n",
    "            soup              = BeautifulSoup(page_source,'lxml')\n",
    "            content           = soup.find('table',{'border':'1', 'align':'center'})\n",
    "            descricoes_leitos = content.find_all('a')\n",
    "            links_tabelas     = ['http://cnes2.datasus.gov.br/'+row.get('href') \n",
    "                                  for row in descricoes_leitos]\n",
    "            \n",
    "            quant_links = len(links_tabelas)\n",
    "            if quant_links == 0: \n",
    "                sucess = False\n",
    "                continue\n",
    "            else: \n",
    "                sucess = True\n",
    "                continue\n",
    "        except requests.ReadTimeout:\n",
    "            sucess = False\n",
    "            continue\n",
    "        except requests.ConnectTimeout:\n",
    "            sucess = False\n",
    "            continue\n",
    "        except requests.ConnectionError:\n",
    "            logging.CRITICAL(\n",
    "                f\"\"\"{datetime.now()}: Erro ao tentar estabelecer conexão com a API.\n",
    "                Por favor, verifique sua conexão com a internet, ou tente novamente em outro momento.\n",
    "                \"\"\")\n",
    "            raise requests.ConnectionError()\n",
    "        \n",
    "        finally:\n",
    "            request_retries += 1\n",
    "            if request_retries >= max_request_retries:\n",
    "                logging.ERROR(\n",
    "                f\"\"\"{datetime.now()}: Máximo de tentativas de request para o url: {url}. \n",
    "                Foram feitas {max_request_retries} tentativas com {request_timeout} segundos de timeout.\n",
    "                \"\"\")\n",
    "                raise MaxRequestRetries('API instável. Por favor, tente novamente em outro momento.')\n",
    "    return links_tabelas\n",
    "\n",
    "def ler_tabela_de_link(url: str, uf: str) -> List[Dict]:\n",
    "    \"\"\" Lê a tabela de leitos contida no link dado\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    url: string\n",
    "        Link da página contendo leitos de um tipo e especialidade, de dado UF\n",
    "    uf: string\n",
    "        Sigla do UF do qual está sendo coletada a tabela de leitos\n",
    "\n",
    "    Retorno\n",
    "    ----------\n",
    "    table: List[Dict]\n",
    "        Tabela de leitos de um tipo e especialidade\n",
    "    \"\"\"\n",
    "    request_retries     = 0\n",
    "    sucess              = False\n",
    "    while not sucess:\n",
    "        try:\n",
    "            page_source = requests.get(url,'lxml',timeout=request_timeout).text\n",
    "            soup = BeautifulSoup(page_source,'lxml')\n",
    "            classificacao_leito = soup.find_all('font',{'color':'#ffcc99', 'face':'verdana,arial', \n",
    "                                                'size': '1'})[1].text.split(' - ')\n",
    "            sucess = True\n",
    "            continue\n",
    "        except IndexError:\n",
    "            sucess = False\n",
    "            continue\n",
    "        except requests.ReadTimeout:\n",
    "            sucess = False\n",
    "            continue\n",
    "        except requests.ConnectTimeout:\n",
    "            sucess = False\n",
    "            continue\n",
    "        except requests.ConnectionError:\n",
    "            logging.CRITICAL(\n",
    "                f\"\"\" {datetime.now()}: Erro ao tentar estabelecer conexão com a API.\n",
    "                Por favor, verifique sua conexão com a internet, ou tente novamente em outro momento.\n",
    "                \"\"\")\n",
    "            raise requests.ConnectionError()\n",
    "                \n",
    "        finally:\n",
    "            request_retries += 1\n",
    "            if request_retries >= max_request_retries:\n",
    "                logging.ERROR(\n",
    "                f\"\"\" {datetime.now()}: Máximo de tentativas de request para o url: {url}. \n",
    "                Foram feitas {max_request_retries} tentativas com {request_timeout} segundos de timeout.\"\"\")\n",
    "                \n",
    "                raise MaxRequestRetries('API instável. Por favor, tente novamente em outro momento.')\n",
    "                \n",
    "    tipo_leito          = classificacao_leito[1][1:].upper()\n",
    "    especialidade_leito = classificacao_leito[-1].upper()\n",
    "\n",
    "    content = soup.find('table',{'border':'1', 'align':'center'})\n",
    "    rows  = content.find_all('tr',{'bgcolor':'#cccccc'})\n",
    "    table  = []\n",
    "\n",
    "    for row in rows:\n",
    "        \n",
    "        columns = [column.text for column in row.find_all('td')]\n",
    "        cnes            = columns[0]\n",
    "        estabelecimento = columns[1].replace(\"\\n\",'')\n",
    "        municipio       = columns[2]\n",
    "        existentes      = int(columns[3])\n",
    "        sus             = int(columns[4])\n",
    "\n",
    "        table.append({'CNES': cnes, 'ESTABELECIMENTO': estabelecimento, 'UF': uf, \n",
    "                       'MUNICIPIO': municipio, 'TIPO': tipo_leito, 'ESPECIALIDADE': especialidade_leito, \n",
    "                       'EXISTENTES': existentes, 'SUS': sus, 'NAO_SUS': existentes-sus})\n",
    "    return table\n",
    "\n",
    "def tab_leitos_por_uf(uf: str, exportar: bool =True, table_name: str ='', \n",
    "                      format: str ='excel', index: bool =False, \n",
    "                      engine: sqlalchemy.engine =None) -> pd.DataFrame:\n",
    "    \"\"\"Coleta a tabela de leitos completa, para dado UF\n",
    "\n",
    "    Parametros\n",
    "    -----------\n",
    "    uf: string\n",
    "        Sigla do UF para coleta da tabela de leitos\n",
    "    exportar: boolean\n",
    "        Quando igual a True, exporta a tabela para um arquivo de formato especificado\n",
    "    table_name: string\n",
    "        Nome da tabela output, sem a extensão, quando exportar=True\n",
    "    format: string\n",
    "        Formato do arquivo, output, quando exportar=True. Os formatos disponíveis estão\n",
    "        listados na função exportar_dataframe\n",
    "    index: boolean\n",
    "        Quando igual a True, inclui a coluna de índice do dataframe no arquivo output\n",
    "    engine: sqlalchemy.engine\n",
    "        Conexão com o banco de dados, quando exportar=True e format='SQL'\n",
    "    \n",
    "    Retorno\n",
    "    -----------\n",
    "    df_leitos_uf: pd.Dataframe\n",
    "        Tabela de leitos completa para o UF dado\n",
    "    \"\"\"\n",
    "    links_tables  = listar_links_tabelas_por_uf(uf)\n",
    "    tab_leitos_uf = []\n",
    "\n",
    "    quant_links = len(links_tables)\n",
    "    for i,link in enumerate(links_tables):\n",
    "        print(f'\\rUF: {uf}. Lendo tabela {i+1} de {quant_links}.',end='')\n",
    "        tab = ler_tabela_de_link(link,uf)\n",
    "        tab_leitos_uf = tab_leitos_uf + tab\n",
    "    df_leitos_uf = pd.DataFrame.from_records(tab_leitos_uf).astype({\n",
    "        'CNES':np.str_, 'ESTABELECIMENTO':np.str_, 'UF':'category', 'TIPO':'category',\n",
    "        'ESPECIALIDADE':'category', 'EXISTENTES':np.int32, 'SUS':np.int32, 'NAO_SUS':np.int32\n",
    "    })\n",
    "    \n",
    "    if exportar:\n",
    "        project_output_dir = project_dir+'/output'\n",
    "        if table_name=='': \n",
    "            table_name = f'Leitos_{uf}'\n",
    "        exportar_dataframe(df=df_leitos_uf,format=format,index=index,filedir=project_output_dir,\n",
    "                           table_name=table_name, engine=engine)\n",
    "    return df_leitos_uf\n",
    "\n",
    "def tab_leitos_brasil(exportar: bool =True, table_name: str ='Leitos_Brasil', \n",
    "                      format: str ='excel', index: bool =False, \n",
    "                      engine: sqlalchemy.engine =None) -> pd.DataFrame:\n",
    "    \"\"\"Coleta a tabela de leitos completa do Brasil\n",
    "\n",
    "    Parametros\n",
    "    -----------\n",
    "    exportar: boolean\n",
    "        Quando igual a True, exporta a tabela para um arquivo de formato especificado\n",
    "    table_name: string\n",
    "        Nome da tabela output, sem a extensão, quando exportar=True\n",
    "    format: string\n",
    "        Formato do arquivo, output, quando exportar=True. Os formatos disponíveis estão\n",
    "        listados na função exportar_dataframe\n",
    "    index: boolean\n",
    "        Quando igual a True, inclui a coluna de índice do dataframe no arquivo output\n",
    "    engine: sqlalchemy.engine\n",
    "        Conexão com o banco de dados, quando exportar=True e format='SQL'\n",
    "    \n",
    "    Retorno\n",
    "    -----------\n",
    "    df_leitos_Brasil: pd.Dataframe\n",
    "        Tabela de leitos completa do Brasil\n",
    "    \"\"\"\n",
    "    UFs = ['RJ', 'SP', 'ES', 'MG', 'SC', 'RS', 'PR', 'DF', 'GO', \n",
    "           'MT', 'MS', 'MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', \n",
    "           'SE', 'BA', 'RO', 'AC', 'AM', 'RR', 'PA', 'AP', 'TO']\n",
    "\n",
    "    df_leitos_brasil = pd.DataFrame(columns=['CNES', 'ESTABELECIMENTO', 'UF', 'MUNICIPIO', 'TIPO', \n",
    "                                             'ESPECIALIDADE', 'EXISTENTES', 'SUS', 'NAO_SUS'])\n",
    "    df_leitos_brasil = df_leitos_brasil.astype({\n",
    "        'CNES':np.str_, 'ESTABELECIMENTO':np.str_, 'UF':'category', 'TIPO':'category',\n",
    "        'ESPECIALIDADE':'category', 'EXISTENTES':np.int32, 'SUS':np.int32, 'NAO_SUS':np.int32\n",
    "    })\n",
    "\n",
    "    print(f'UFs para coleta: {UFs}')\n",
    "    for uf in UFs:\n",
    "        df_leitos_uf     = tab_leitos_por_uf(uf=uf,exportar=False)\n",
    "        df_leitos_brasil = pd.concat([df_leitos_brasil,df_leitos_uf])\n",
    "    print('\\n')\n",
    "    \n",
    "    if exportar: \n",
    "        project_output_dir = project_dir+'/output'\n",
    "        exportar_dataframe(df=df_leitos_brasil, format=format, index=index,\n",
    "                           filedir=project_output_dir, table_name=table_name, engine=engine)\n",
    "    return df_leitos_brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
